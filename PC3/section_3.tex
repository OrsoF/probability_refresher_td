\begin{center}
  \section*{Convergence}
\end{center}

%%% Exercice 6 %%%

\begin{Exercise}
  Let ${\left\{X_{i}\right\}}_{i \geq 0}$ be a sequence of i.i.d. Bernoulli variables with parameter $\theta$.
  \begin{enumerate}
    \item Show that $\sqrt{n}\left(\bar{X}_{n}-\theta\right)
            \stackrel{d}{\longrightarrow} \mathcal{N}(0, \theta(1-\theta))$, where
          $\bar{X}_{n}=n^{-1} \sum_{i=1}^{n} X_{i}$.

    \item Show that $\bar{X}_{n}\left(1-\bar{X}_{n}\right) \stackrel{P}{\longrightarrow}
            \theta(1-\theta)$.

    \item Show that $\sqrt{n}{\left(\bar{X}_{n}-\theta\right)}^{2}
            \stackrel{P}{\longrightarrow} 0$.

    \item Determine the limit distribution of
          $\sqrt{n}\left(\bar{X}_{n}\left(1-\bar{X}_{n}\right)-\theta(1-\theta)\right)$.

  \end{enumerate}
\end{Exercise}

%%% Solution 6 %%%

\begin{solution}
  \begin{enumerate}
    \item Using Central Limit Theorem, we have:
          \begin{align*}
            \sqrt{n} ( \bar{X}_n - \theta) & = \sqrt{n} ( \bar{X}_n -
            \esperance{X_1})                                                                 \\
                                           & \overset{d}{\rightarrow} \mathcal N(0,Var(X_1)) \\
                                           & = \mathcal N(0,\theta(1-\theta))
          \end{align*}
    \item Applying Law of Large Numbers, we have $\bar{X}_n \overset{P}{\rightarrow}\esperance{X_1}=\theta$.
          The function $h(x)=x(1-x)$ being continuous, we obtain
          \[
            \bar{X}_n (1-\bar{X}_n) = h(\bar{X}_n) \overset{P}{\rightarrow} h(\theta) = \theta(1-\theta)
          \]
          applying continuity theorem.
    \item We have
          \[
            \sqrt{n} {( \bar{X}_n - \theta)}^2 = \sqrt{n} ( \bar{X}_n - \theta)( \bar{X}_n - \theta)
          \]
          but
          \[
            \sqrt{n} ( \bar{X}_n - \theta) \overset{d}{\rightarrow} \mathcal N (0,\theta(1-\theta))
          \]
          and $( \bar{X}_n - \theta) \overset{d}{\rightarrow} 0$. Finally
          \[
            \sqrt{n} {( \bar{X}_n - \theta)}^2 \overset{d}{\rightarrow} 0
          \]
          As convergence in law towards a constant is equivalent to the probability convergence, we can extrapolate the wanted result.
    \item We write
          \begin{align*}
            \sqrt{n} \left( \bar{X}_n (1 - \bar{X}_n) - \theta(1-\theta) \right)
             & = \sqrt{n} \left( (\bar{X}_n-\theta) (1 - \bar{X}_n)+\theta(1 - \bar{X}_n) - \theta(1-\theta) \right) \\
             & = \sqrt{n} \left( (\bar{X}_n-\theta) (1 - \bar{X}_n)-\theta( \bar{X}_n -\theta) \right)               \\
          \end{align*}
          but
          \[
            \sqrt{n} (\bar{X}_n-\theta) \overset{d}{\rightarrow} \mathcal N (0,\theta(1-\theta))
          \]
          and
          \[
            (1 - \bar{X}_n-\theta) \overset{P}{\rightarrow} (1-2\theta)
          \]
          Therefore,
          \[
            \left( \bar{X}_n (1 - \bar{X}_n) - \theta(1-\theta) \right) \overset{d}{\rightarrow} (1-2\theta) N (0,\theta(1-\theta)) = N (0, \theta(1-\theta){(1-2\theta)}^2)
          \]
          applying Slutsky theorem.
  \end{enumerate}
\end{solution}

%%% Exercice 7 %%%

\begin{Exercise}
  Let ${\left(X_{n}\right)}_{n \geq 1}$ be a sequence of i.i.d.\,square-integrable random variables with mean $m$ and variance $\sigma^{2}>0$. Denote $\bar{X}_{n}=\frac{1}{n} \sum_{i=1}^{n} X_{i}$ and $\hat{\sigma}_{n}^{2}=\frac{1}{n} \sum_{i=1}^{n}{\left(X_{i}-\bar{X}_{n}\right)}^{2}$.

  \begin{enumerate}
    \item Show that $\hat{\sigma}_{n}^{2}$ converges in probability to $\sigma^{2}$ as $n
            \rightarrow \infty$.

    \item Determine the limit distribution of $\sqrt{n}\left(\bar{X}_{n}-m\right) /
            \hat{\sigma}_{n}$.

  \end{enumerate}
\end{Exercise}

%%% Solution 7 %%%

\begin{solution}
  Let us study the limit case of $\hat{\sigma}_n^2$ when $n\to +\infty$. We have:
  \begin{align*}
    (n-1)\hat{\sigma}_n^2
     & =\sum_{k=1}^n{(X_k-\bar X_n)}^2                                                  \\
     & = \sum_{k=1}^n{(X_k-m)}^2 + 2\sum_{k=1}^n(X_k-m)(m-\bar X_n) + n{(m-\bar X_n)}^2 \\
     & = \sum_{k=1}^n{(X_k-m)}^2 - n{(m-\bar X_n)}^2.
  \end{align*}
  So
  \begin{align*}
    \frac{n-1}{n}\hat{\sigma}_n^2 & = \frac{1}{n}\sum_{k=1}^n(X_k-m)^2 - {(m-\bar X_n)}^2                            \\
                                  & \overset{a.s.}{\longrightarrow}\esperance{{(X_1-m)}^2} - 0 = \mathrm{Var}(X_1)=:
    \sigma^2,
  \end{align*}
  Here, the limit is given by the Law of Large Numbers. As a result, $\hat{\sigma}_n \to \sigma$ almost surely. Let us note $Z_n := \sqrt{n}(\bar X_n-m)$. Applying Central Limit Theorem, $Z_n$ converges in law to a gaussian random variable $Z\sim \mathcal{N}(0,\sigma^2)$. According to Slutsky theorem, the couple $(Z_n,\hat{\sigma}_n^{-1})$ converges in law to $(Z,\sigma^{-1})$. In particular, the product function being continuous, $\frac{Z_n}{\hat{\sigma}_n} \overset{d}{\rightarrow} Z/\sigma \sim \mathcal{N}(0,1)$
\end{solution}

%%% Exercice 8 %%%

\begin{Exercise}
  (Poisson model). Let $\left(X_{1}, \ldots, X_{n}\right)$ be an i.i.d. sample from the Poisson distribution with unknown parameter $\lambda>0$. Denote $\bar{X}_{n}=\frac{1}{n} \sum_{i=1}^{n} X_{i}$.

  \begin{enumerate}
    \item Show that $\bar{X}_{n}$ is an unbiased estimator of $\lambda$, that is
          $\mathbb{E}\left[\bar{X}_{n}\right]=\lambda$.

    \item Show that $\bar{X}_{n}$ converges in probability to $\lambda$ when $n$ tends to
          infinity.

    \item Determine the limit distribution of $\sqrt{n}\left(\bar{X}_{n}-\lambda\right) /
            \sqrt{\bar{X}_{n}}$.

    \item Find an appropriate function $g$ such that
          $\sqrt{n}\left(g\left(\bar{X}_{n}\right)-g(\lambda)\right)
            \stackrel{d}{\longrightarrow} \mathcal{N}(0,1)$.

  \end{enumerate}
\end{Exercise}

%%% Solution 8 %%%

\begin{solution}
  \begin{enumerate}
    \item We recall that, for $X \sim \mathcal P(\lambda)$ and $\lambda>0$, we have
          $\esperance{X} = \var{X} = \lambda$.

          Then, the estimator $\bar X_n$ is therefore unbiased ($ \esperance{\bar X_n} = \lambda $) and consistant using the Strong Law of Large Numbers
          ($ \bar X_n\longrightarrow \esperance{X_1} = \lambda~p.s$). Finally, $\bar{X}_n$
          is asymptotically normal using the Central Limit Theorem:
          \[
            \sqrt{n} ({\bar{X}}_n - \lambda) = \sqrt{n} ( \bar X_n - \esperance{X_1}) \stackrel{\mathcal
              L}\longrightarrow\mathcal N(0,\var{X_1})=\mathcal
            N(0,\lambda) \text{ when } n \to \infty
          \]

    \item Using the previous question and Slutsky theorem, we get
          \begin{align*}
            \sqrt{n} \left(\frac{\bar X_n-\lambda}{\sqrt{\bar X_n}} \right)
             & = \underbrace{ \sqrt n \left(\frac{\bar X_n-\lambda}{\sqrt{\lambda}} \right) }_{\stackrel{\mathcal L}\longrightarrow\mathcal N(0,1)} \underbrace{\frac{\sqrt{\lambda}}{\sqrt{\bar X_n}}}_{\stackrel{P}\longrightarrow \frac{\sqrt{\lambda}}{\sqrt{\esperance{X_1}}}=1}
            \stackrel{\mathcal L}\longrightarrow \normal{0}{1}
          \end{align*}
    \item Applying Delta method, for any function $g$ continuously differentiable on $\R_+$, we got
          \[
            \sqrt{n} \left(g(\bar X_n)-g(\lambda) \right)\stackrel{\mathcal L}\longrightarrow \normal{0}{{g'(\lambda)}^2\var{X}}
          \]
          We are looking for a function $g$ with $1$ as a limit variance. This means that
          \[
            {(g'(\lambda))}^2\var(X)=1
            \Leftrightarrow {(g'(\lambda))}^2 = \frac1\lambda
          \]
          We therefore can choose $g(u) = 2\sqrt u$ with, as a derivative, $g'(u)= 1/\sqrt u$ and we get
          \[
            \sqrt n
            \left(2\sqrt{\bar X_n}-2\sqrt \lambda \right)\stackrel{\mathcal
              L}\longrightarrow\mathcal
            N\left(0,{\left(\frac1{\sqrt\lambda}\right)}^2\lambda\right)=\mathcal N(0,1).
          \]
  \end{enumerate}
\end{solution}

%%% Exercice 9 %%%

\begin{Exercise}
  Let $X \sim \normal{0}{1}$. Let $ Y := \indicator{X < \theta} $ for $\theta \in \R$. We observe a sample $Y_{1}, \ldots, Y_{n}$ of i.i.d.\,realizations of $Y$ and suppose that parameter $\theta$ is unknown.
  Denote by $\Phi$ the cumulative distribution function of the standard normal
  distribution $\mathcal{N}(0,1)$. An estimator $\hat{\theta}_{n}$ of $\theta$ is
  given by
  \[
    \hat{\theta}_{n}=\Phi^{-1}\left(\bar{Y}_{n}\right)
  \]
  where $\bar{Y}_{n}=\frac{1}{n} \sum_{i=1}^{n} Y_{i}$

  \begin{enumerate}
    \item Determine the distribution of $Y$.
    \item Study the convergence in probability of $\hat{\theta}_{n}$ towards $\theta$
          when $n$ tends to infinity.
    \item Study the limit distribution of $\sqrt{n}\left(\hat{\theta}_{n}-\theta\right)$.
  \end{enumerate}
\end{Exercise}

%%% Solution 9 %%%

\begin{solution}
  \begin{enumerate}
    \item
          As $Y$ takes its values $\{0,1\}$, $Y$ follows a Bernoulli law with parameter $\proba{Y=1} = \proba{\theta>\xi} = \Phi(\theta)$

    \item
          As $\frac1n\sum_{i=1}^n Y_i\to\esperance{}[Y_1]=\Phi(\theta)$ a.s and $\Phi^{-1}$ is a continuous function, we have $\hat \theta_n=\Phi^{-1}(\frac1n\sum_{i=1}^n Y_i)\to
            \Phi^{-1}(\Phi(\theta))=\theta~p.s$. Therefore, $\hat\theta_n$ is consistant for $\theta$.

    \item
          According to CLT, (as $\esperance{Y^2_1}<\infty$), we have $\sqrt
            n(\frac1n\sum_{i=1}^n Y_i-\Phi(\theta))\stackrel{\mathcal
              L}\longrightarrow\mathcal N(0,\var(Y_1))=\mathcal
            N(0,\Phi(\theta)(1-\Phi(\theta)))$. The function $\Phi^{-1}(\theta)$ is
          continuously differentiable with derivative $(\Phi^{-1})'(\theta) =
            1/\varphi(\Phi^{-1}(\theta))$. Applying Delta method, we obtain :
          \begin{align*}
            \sqrt n(\hat\theta_n-\theta) =\sqrt n\left(\Phi^{-1}\left(\frac1n\sum_{i=1}^n Y_i\right)-\Phi^{-1}(\Phi(\theta))\right)
             & \stackrel{\mathcal L}\longrightarrow \mathcal N(0, {((\Phi^{-1})'(\Phi(\theta)))}^2   \Phi(\theta)(1-\Phi(\theta))) \\
             & =\mathcal N\left(0, \frac{  \Phi(\theta)(1-\Phi(\theta))}{ \varphi^2(\theta)}\right)
          \end{align*}

  \end{enumerate}
\end{solution}